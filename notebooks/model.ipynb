{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b1f4e39-3361-4314-a3e3-d31c266b896e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olive\\Projects\\predictive-bill-tracker\\env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Accuracy: 0.8409\n",
      "ARIMA Forecast: [993571.69847073 989759.25659001 988778.41586316 989269.77398506\n",
      " 992872.70447619]\n",
      "Epoch 0, Loss: 0.9899, Pred: 0.6284\n",
      "Epoch 10, Loss: 0.8581, Pred: 0.5760\n",
      "Epoch 20, Loss: 0.7714, Pred: 0.5376\n",
      "Epoch 30, Loss: 0.7010, Pred: 0.5039\n",
      "Epoch 40, Loss: 0.6969, Pred: 0.5019\n",
      "Epoch 50, Loss: 0.6963, Pred: 0.5016\n",
      "Epoch 60, Loss: 0.6957, Pred: 0.5013\n",
      "Epoch 70, Loss: 0.6950, Pred: 0.5009\n",
      "Epoch 80, Loss: 0.6944, Pred: 0.5006\n",
      "Epoch 90, Loss: 0.6939, Pred: 0.5004\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('../data/processed.csv', encoding='utf-8')\n",
    "required_cols = ['yea_count', 'nay_count', 'nominate_mid_1', 'nominate_mid_2', 'cumulative_rolls', 'action_count', 'sentiment', 'date']\n",
    "for col in required_cols:\n",
    "    if col not in df.columns:\n",
    "        print(f'Warning: {col} missing; using default 0')\n",
    "        df[col] = 0 if col != 'date' else pd.to_datetime('2023-01-01')\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Logistic Regression\n",
    "X = df[['yea_count', 'nay_count', 'nominate_mid_1', 'nominate_mid_2', 'cumulative_rolls', 'action_count', 'sentiment']]\n",
    "y = df['passed']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "model_lr = LogisticRegression()\n",
    "model_lr.fit(X_train, y_train)\n",
    "preds_lr = model_lr.predict(X_test)\n",
    "print(f'Logistic Accuracy: {accuracy_score(y_test, preds_lr):.4f}')\n",
    "joblib.dump(model_lr, '../models/logistic_model.pkl')\n",
    "\n",
    "# Time-Series (ARIMA on cumulative_rolls grouped by date)\n",
    "ts_data = df.groupby('date')['cumulative_rolls'].mean()\n",
    "ts_data = ts_data.asfreq('D', fill_value=0)  # Daily frequency, fill missing\n",
    "model_arima = ARIMA(ts_data, order=(5,1,0))\n",
    "model_fit = model_arima.fit()\n",
    "forecast = model_fit.forecast(steps=5)\n",
    "print(f'ARIMA Forecast: {forecast.values}')\n",
    "joblib.dump(model_fit, '../models/arima_model.pkl')\n",
    "\n",
    "# GNN Layer (pure PyTorch)\n",
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, input_dim: int, output_dim: int, A: torch.Tensor):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.A = A.float()\n",
    "        self.A_hat = self.A + torch.eye(self.A.size(0))\n",
    "        degrees = torch.sum(self.A_hat, dim=1)\n",
    "        self.D_neg_sqrt = torch.diag(torch.pow(degrees, -0.5))\n",
    "        self.W = nn.Parameter(torch.rand(input_dim, output_dim))\n",
    "\n",
    "    def forward(self, X: torch.Tensor):\n",
    "        support = torch.matmul(self.D_neg_sqrt, torch.matmul(self.A_hat, self.D_neg_sqrt))\n",
    "        aggregated = torch.matmul(support, torch.matmul(X, self.W))\n",
    "        return F.relu(aggregated)\n",
    "\n",
    "# Full GNN Model\n",
    "class GNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, A):\n",
    "        super(GNN, self).__init__()\n",
    "        self.gcn1 = GCNLayer(input_dim, hidden_dim, A)\n",
    "        self.gcn2 = GCNLayer(hidden_dim, output_dim, A)\n",
    "\n",
    "    def forward(self, X):\n",
    "        x = self.gcn1(X)\n",
    "        x = self.gcn2(x)\n",
    "        x = torch.mean(x, dim=0)  # Graph-level mean pool\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "# Mock graph (adapt with real sponsor data later)\n",
    "num_nodes = 10\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(range(num_nodes))\n",
    "G.add_edges_from([(0,1), (1,2), (2,3), (3,0), (4,5), (5,6)])\n",
    "adj = nx.adjacency_matrix(G).todense()\n",
    "A = torch.tensor(adj, dtype=torch.float)\n",
    "\n",
    "# Node features: Use processed features\n",
    "X_gnn = torch.tensor(df[['nominate_mid_1', 'nominate_mid_2']].values[:num_nodes], dtype=torch.float)\n",
    "y_gnn = torch.tensor([df['passed'].values[0]], dtype=torch.float)\n",
    "\n",
    "# Train GNN\n",
    "model_gnn = GNN(input_dim=2, hidden_dim=16, output_dim=1, A=A)\n",
    "optimizer = torch.optim.Adam(model_gnn.parameters(), lr=0.01)\n",
    "criterion = nn.BCELoss()\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    pred = model_gnn(X_gnn)\n",
    "    loss = criterion(pred, y_gnn)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item():.4f}, Pred: {pred.item():.4f}')\n",
    "\n",
    "torch.save(model_gnn.state_dict(), '../models/gnn_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b51817-d303-4701-9335-4b8416341b4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
